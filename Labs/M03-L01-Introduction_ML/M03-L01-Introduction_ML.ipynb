{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Introdução ao Aprendizado de Máquinas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enquanto analista de dados ou cientista de dados, você vai descobrir que, enquanto usar algoritmos de aprendizado de máquina é a parte divertida e glamurosa do trabalho, preparar os dados toma até uns 90% do seu tempo... Portanto, aprender a preparar seus dados é uma das habilidades mais importantes que você vai precisar.\n",
    "## Recursos\n",
    "\n",
    "[Interpolação Linear](https://en.wikipedia.org/wiki/Linear_interpolation)\n",
    "\n",
    "[Atribuição de Dados Ausentes](http://www.stat.columbia.edu/~gelman/arm/missing.pdf)\n",
    "\n",
    "[7 Passos para Preparação de Dados](https://www.kdnuggets.com/2017/06/7-steps-mastering-data-preparation-python.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importe suas bibliotecas aqui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 1 - Importe e descreva o dataset\n",
    "\n",
    "- Neste desafio, usaremos o dataset `austin_weather`.\n",
    "- Importe-o para um dataframe chamado `austin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em seguida, descreva o dataset que criou:\n",
    "- Olhe as variáveis e seus tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analise as estatísticas descritivas dos valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Olhe as cinco primeiras linhas de todas as variáveis, pra avaliar as variáveis categóricas também"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na célula abaixo, escreva 3 informações que você apreendeu ao analisar o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _Suas observações deveriam incluir:_\n",
    "\n",
    "_1. Há 21 variáveis no dataset. 3 delas são numéricas, as demais estão classificadas como objetos._\n",
    "\n",
    "_2. A temperatura média em Austin variou entre 70°F e 93°F. A temperatura máxima observada durante o período foi 107°F, e a mínima, 19°F._\n",
    "\n",
    "_3. Olhando para as primeiras linhas, percebemos que muitas variáveis apresentam dados numéricos - apesar de estarem classificadas como objetos. Isso significa que talvez precisemos fazer alguma limpeza._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos analisar a variável `DewPointAvgF` usando `unique()`, a fim de listar os valores únicos nesta coluna.\n",
    "\n",
    "Descreva o que você percebeu. Por que você acha que o Pandas considerou esta coluna `object` ao invés de `int64`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A seguir, temos uma lista com todas as colunas erroneamente classificadas como `object`.\n",
    "- Use esta lista para consertar a classificação delas para numérica usando `pandas.to_numeric`. Se você encontrar erros ao converter strings para numéricos, pode forçar a conversão ao acrescentar o argumento `errors = \"coerce\"`. Essa coerção vai substituir elementos não-conversíveis por `NaN` - isso é conveniente, pois lidaremos com valores ausentes na sequência.\n",
    "\n",
    "*Dica: você pode usar um loop para converter uma coluna de cada vez, mas seria mais eficiente usar `apply`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_tipo_errado = ['DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', \n",
    "                      'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', \n",
    "                      'SeaLevelPressureAvgInches' ,'SeaLevelPressureLowInches', 'VisibilityHighMiles',\n",
    "                      'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', \n",
    "                      'WindGustMPH', 'PrecipitationSumInches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirme que seu código funcionou, checando os tipos dos dados novamente.\n",
    "- Deve haver somente duas colunas `object` agora (`Date` and `Events`). As demais devem ser `int64` ou `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 2 - Lidar com os dados ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora que consertamos os tipos, vamos lidar com valores nulos\n",
    "- O primeiro passo é observar quantas linhas contêm valores ausentes.\n",
    "- Para isso, podemos usar o método `.isnull()`. Se queremos achar as linhas que têm **pelo menos um** valor nulo, acrescentamos o método `.any(axis=1)`. Então, `austin.isnull().any(axis=1)` vai retornar uma série com verdadeiros e falsos - uma máscara. Para obter um dataframe somente com as linhas que possuem algum valor nulo, precisamos aplicar esta máscara ao dataframe original.\n",
    "- Armazene o novo dataframe numa variável chamada `valores_ausentes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Há várias estratégias para lidar com dados ausentes. A seguir, listamos as mais usadas pelos cientistas de dados:\n",
    "> - Remover todas as linhas e/ou colunas que contenham valores nulos. Esta é a estratégia mais simples - ela pode funcionar em alguns casos...\n",
    "> - Substituir todos os valores nulos por um valor que não influencie muito a análise.\n",
    "\n",
    "    - Para variáveis categóricas, `0`, `-1` e `9999` são valores comumente usados. \n",
    "    - Para variáveis contínuas, alguns usam a média dos valores presentes. Esta estratégia não é ótima, pois pode aumentar o fit do modelo.\n",
    "    \n",
    "> - Preencher os dados usando algum algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No nosso caso, vamos usar duas abordagens:\n",
    "> - Primeiro, vamos remover as linhas que contêm majoritariamente valores ausentes;\n",
    "> - Depois, vamos preencher os demais nulos através do algoritmo de _interpolação linear_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora, conte o número de linhas em `austin` e em `valores_ausentes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcule a razão dos valores ausentes em relação ao total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como você pode perceber, temos uma proporção grande de valores nulos (mais de 10%). Talvez devamos avaliar quais colunas têm a maioria desses valores nulos, e remover essas colunas... Nas colunas restantes, faremos a aproximação linear dos dados ausentes.\n",
    "\n",
    "- Podemos achar o número de linhas ausentes em cada coluna usando o método `.isna()` seguido do método `.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como podemos observar, a maioria dos dados ausentes está na coluna `PrecipitationSumInches`.\n",
    "- Qual é a proporção de valores nulos nesta coluna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mais de 10% de valores nulos! Bora remover essa coluna aí... \n",
    "- Não faz sentido preencher tantas linhas com valores estimados..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remova essa coluna de `austin` usando o método `.drop()`, com o argumento `inplace = True`.\n",
    "\n",
    "*Lembretes:*\n",
    "\n",
    "* Ao usar `inplace = True`, o dataframe original é alterado, e o código não dá retorno. Caso não seja especificado o `inplace`, ele será assumido como `False` (valor padrão desse argumento), e o código vai retornar uma demonstração do dataframe transformado - mas o dataframe original **não** será alterado. Neste caso, para alterar o dataframe original, precisamos atribuir o código à variável-nome do dataframe, sobrescrevendo-a.\n",
    "\n",
    "* Além disso, ao remover coluna(s) ao invés de linha(s), precisamos especificar o argumento `axis = 1` no método `.drop()`, ou usar o argumento `columns`.\n",
    "\n",
    "[documentação do método `pandas.DataFrame.drop()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprima `austin` para confirmar que a coluna foi de fato removida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora, vamos fazer a interpolação linear dos dados ausentes.\n",
    "\n",
    "- Isso significa que usaremos um algoritmo linear para estimar os dados ausentes.\n",
    "- Interpolação linear assume que há um linha reta entre os pontos, e os valores ausentes serão estimados nesta linha. Essa é uma aproximação suficientemente boa para dados relacionados a clima. Dados relacionados a clima costumam ser séries temporais - não queremos remover linhas do dataset, se possível - então, é preferível estimar os valores ausentes. Entretanto, se você tiver dados sobre um único momento, talvez seja melhor remover linhas... \n",
    "\n",
    "_Se quiser ler mais sobre interpolação linear, [wikipedia](https://en.wikipedia.org/wiki/Linear_interpolation)._\n",
    "\n",
    "- Na célula a seguir, use o método `.interpolate()` no dataframe inteiro. Desta vez, passe o argumento `inplace=False`, e atribua o resultado a uma nova variável, chamada `austin_fixed`, para que possamos compará-lo com `austin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirme que `austin_fixed` não tem valores nulos. (Também confirme que `austin` ainda os tem.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 3 - Processando a coluna `Events`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nosso dataframe contém uma coluna verdadeiramente textual - a coluna `Events`. Devemos analisar esta coluna para determinar como processá-la.\n",
    "- Use o método `value_counts()` para analisá-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lendo os valores de `Events` e refletindo sobre o que esses valores significam no contexto dos dados, a que conclusão você chega?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual é o maior número de eventos ocorridos num único dia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queremos transformar o tipo da coluna `Events` para numérico. Isso vai permitir que apliquemos algoritmos de aprendizado de máquina facilmente.\n",
    "\n",
    "- Como? Vamos criar uma nova coluna para cada tipo de evento. Em cada coluna, usaremos `1` para indicar que naquele dia tal evento ocorreu, e `0` caso contrário.\n",
    "\n",
    "Abaixo, fornecemos uma lista com todos os tipos de eventos. Crie, em `austin_fixed`, uma nova coluna para cada elemento da lista, atribuindo a todas as células das colunas criadas, a princípio, o valor `0`.\n",
    "\n",
    "```python\n",
    "lista_eventos = ['Snow', 'Fog', 'Rain', 'Thunderstorm']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprima o novo dataframe para confirmar se as colunas novas foram criadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em seguida, vamos atribuir os devidos valores às novas colunas de `austin_fixed`.\n",
    "\n",
    "- Vamos checar a coluna `Events`. Se uma string contiver `Rain`, então à coluna `Rain` devemos atribuir `1`; se não, mantemos o `0`.\n",
    "- Faremos o mesmo procedimento para as demais novas colunas.\n",
    "\n",
    "*Dicas:*\n",
    "\n",
    "* Use [`pandas.Series.str.contains()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html) para atribuir os novos valores.\n",
    "\n",
    "* E se os novos valores forem boleanos ao invés de números? Podemos transformar os valores boleanos em números com o método `.astype(int)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cheque as primeiras linhas de `austin_fixed` para conferir se as colunas de eventos estão com os valores que queríamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora, podemos remover a coluna `Events`, já que sua informação foi armazenada nas demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 4 - Processando a coluna `Date`\n",
    "- `Date` é outra coluna não-numérica em nosso dataset. Os valores desta coluna estão no formato `'2014-01-06'` (ano, mês e dia, conectados por hífen).\n",
    "- Um jeito de converter a data em numérico é usando uma abordagem parecida com a que usamos em `Events`, separando as strings pelos hífens e atribuindo cada elemento a colunas novas - `Year`, `Month` e `Day`.\n",
    "- Mas, neste desafio, vamos fazer de outro jeito: usando o método `toordinal()` da biblioteca `datetime`. Dependendo de qual análise com aprendizado de máquina formos conduzir, cada método terá seus prós e contras. Nosso propósito hoje é praticar preparação de dados, então vamos pular essa discussão aqui.\n",
    "\n",
    "Aqui, você pode achar a [referência](https://docs.python.org/3/library/datetime.html#datetime.date.toordinal) e um [exemplo](https://stackoverflow.com/questions/39846918/convert-date-to-ordinal-python) de uso de `toordinal`. O processo consiste em, primeiramente, converter a string para `datetime`, usando `datetime.datetime.strptime`, e então converter `datetime` para numérico através de `toordinal`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na célula abaixo, converta a coluna `Date` em numérica, usando o método `toordinal()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cheque `austin_fixed` para conferir a coluna `Date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 5 - Conjuntos de Amostragem e de Validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora que processamos os dados para aprendizado de máquina, vamos separá-los em conjuntos de treino e de teste.\n",
    "- Primeiro treinamos o modelo usando somente o conjunto de treino.\n",
    "- Avaliamos os resultados no conjunto treino.\n",
    "- Então aplicamos o modelo no conjunto teste e avaliamos esses resultados também.\n",
    "- Se as métricas de avaliação forem significativamente melhores no conjunto treino, então sabemos que nosso modelo sobreajustou.\n",
    "- Precisaremos revisar nosso modelo para assegurar que funcione bem também para dados fora dos conjuntos treino e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na próxima célula, separaremos os dados em conjuntos de treino e de teste, usando o método `train_test_split()` da biblioteca `scikit-learn`.\n",
    "\n",
    "- Quando usamos a biblioteca `scikit-learn` para aprendizado de máquina, primeiro separamos nossos dados em variáveis de previsão e de resposta. Este é o modo padrão de entrada de datasets em modelos da `scikit-learn`.\n",
    "\n",
    "Na próxima célula, designe a coluna `TempAvgF` à variável `y` (que será uma série), e as demais colunas, à variável `X` (que será um dataframe). `X` deverá conter as seguintes colunas:\n",
    "\n",
    " `['Date',\n",
    " 'TempHighF',\n",
    " 'TempLowF',\n",
    " 'DewPointHighF',\n",
    " 'DewPointAvgF',\n",
    " 'DewPointLowF',\n",
    " 'HumidityHighPercent',\n",
    " 'HumidityAvgPercent',\n",
    " 'HumidityLowPercent',\n",
    " 'SeaLevelPressureHighInches',\n",
    " 'SeaLevelPressureAvgInches',\n",
    " 'SeaLevelPressureLowInches',\n",
    " 'VisibilityHighMiles',\n",
    " 'VisibilityAvgMiles',\n",
    " 'VisibilityLowMiles',\n",
    " 'WindHighMPH',\n",
    " 'WindAvgMPH',\n",
    " 'WindGustMPH',\n",
    " 'Snow',\n",
    " 'Fog',\n",
    " 'Rain',\n",
    " 'Thunderstorm']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na próxima célula, importe `train_test_split` da `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agora que separamos os dados em variáveis de previsão e de resposta, e importamos o método `train_test_split()`, vamos separar `X` e `y` em `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "- 80% dos dados devem estar no conjunto treino, e 20% no teste. A documentação de `train_test_split()` pode ser acessada [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parabéns! Você terminou a preparação do dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio-Bônus\n",
    "\n",
    "### Enquanto o procedimento acima é a prática comum para preparar a maioria dos datasets, quanto se trata de dados de série temporal, às vezes não podemos separar treino e teste de forma aleatória...\n",
    "\n",
    "- Isso porque, muitas vezes, algoritmos de séries temporais dependem da distância constante entre as observações.\n",
    "- Nesses casos, geralmente selecionamos a maioria das linhas do começo do dataset como treino, e as demais, do final, como teste.\n",
    "- Não usamos `train_test_split()` pois o método separa os dados aleatoriamente.\n",
    "\n",
    "Na célula a seguir, calcule o número de linhas que equivale a 80% do dataset (se necessário, arredonde para o próximo inteiro). Designe este número à variável `ts_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designe as primeiras `ts_rows` linhas de `X` para `X_ts_train`, e as demais, para `X_ts_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designe as primeiras `ts_rows` linhas de `y` para `y_ts_train`, e as demais, para `y_ts_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7869b160c3910301faef0a277a4870fbba5b5242c72c77312845f42f06961f70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
